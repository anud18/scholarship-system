# Example Production Backup Workflow
# Copy this file to your production repository at: .github/workflows/backup.yml
#
# NOTE: This workflow creates backups on the production server.
# Database VM does NOT have internet access, so backups are stored locally
# for IT staff to transfer to external storage.

name: Backup Production Data

on:
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
    - cron: '0 */6 * * *'  # Every 6 hours (for more frequent backups)
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Type of backup'
        required: true
        type: choice
        options:
          - full
          - database-only
          - files-only
        default: 'full'
      retention_days:
        description: 'Keep backups for N days'
        required: false
        type: number
        default: 7

env:
  # Backup directory on production server (must exist and be writable)
  BACKUP_DIR: /var/backups/scholarship-system
  RETENTION_DAYS: 7  # Keep backups for 7 days on server

jobs:
  backup-database:
    name: Backup PostgreSQL Database
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'schedule' ||
      github.event.inputs.backup_type == 'full' ||
      github.event.inputs.backup_type == 'database-only'

    steps:
      - name: Create database backup on server
        id: db-backup
        env:
          SSH_PRIVATE_KEY: ${{ secrets.PRODUCTION_SSH_KEY }}
          SERVER_HOST: ${{ secrets.PRODUCTION_SERVER }}
          SERVER_USER: ${{ secrets.PRODUCTION_USER }}
          RETENTION: ${{ github.event.inputs.retention_days || env.RETENTION_DAYS }}
        run: |
          BACKUP_TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          BACKUP_DATE=$(date +%Y%m%d)
          BACKUP_FILE="database-backup-${BACKUP_TIMESTAMP}.sql.gz"

          mkdir -p ~/.ssh
          echo "$SSH_PRIVATE_KEY" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H "$SERVER_HOST" >> ~/.ssh/known_hosts

          # Create backup directory structure on server
          ssh -i ~/.ssh/deploy_key "$SERVER_USER@$SERVER_HOST" << ENDSSH
            # Ensure backup directory exists
            sudo mkdir -p ${BACKUP_DIR}/database/${BACKUP_DATE}
            sudo chown -R $SERVER_USER:$SERVER_USER ${BACKUP_DIR}
            chmod 750 ${BACKUP_DIR}

            echo "ðŸ“ Backup directory: ${BACKUP_DIR}/database/${BACKUP_DATE}"

            # Create database backup
            cd /opt/scholarship-system
            docker compose exec -T postgres pg_dump \
              -U scholarship_user \
              -d scholarship_db \
              --format=custom \
              --compress=9 \
              | gzip > ${BACKUP_DIR}/database/${BACKUP_DATE}/${BACKUP_FILE}

            # Verify backup was created
            if [ -f ${BACKUP_DIR}/database/${BACKUP_DATE}/${BACKUP_FILE} ]; then
              BACKUP_SIZE=\$(du -h ${BACKUP_DIR}/database/${BACKUP_DATE}/${BACKUP_FILE} | cut -f1)
              echo "âœ… Database backup created: ${BACKUP_FILE} (\${BACKUP_SIZE})"
              echo "ðŸ“ Location: ${BACKUP_DIR}/database/${BACKUP_DATE}/${BACKUP_FILE}"

              # Set permissions for IT access
              chmod 640 ${BACKUP_DIR}/database/${BACKUP_DATE}/${BACKUP_FILE}
            else
              echo "::error::Failed to create database backup"
              exit 1
            fi

            # Create checksum for integrity verification
            cd ${BACKUP_DIR}/database/${BACKUP_DATE}
            sha256sum ${BACKUP_FILE} > ${BACKUP_FILE}.sha256
            echo "ðŸ” Checksum created"
          ENDSSH

          echo "backup_file=${BACKUP_FILE}" >> $GITHUB_OUTPUT
          echo "backup_date=${BACKUP_DATE}" >> $GITHUB_OUTPUT

      - name: Cleanup old backups on server
        env:
          SSH_PRIVATE_KEY: ${{ secrets.PRODUCTION_SSH_KEY }}
          SERVER_HOST: ${{ secrets.PRODUCTION_SERVER }}
          SERVER_USER: ${{ secrets.PRODUCTION_USER }}
          RETENTION: ${{ github.event.inputs.retention_days || env.RETENTION_DAYS }}
        run: |
          ssh -i ~/.ssh/deploy_key "$SERVER_USER@$SERVER_HOST" << ENDSSH
            # Calculate cutoff date
            CUTOFF_DATE=\$(date -d "${RETENTION} days ago" +%Y%m%d)
            echo "ðŸ—‘ï¸  Cleaning up backups older than \${CUTOFF_DATE}"

            # Find and delete old backup directories
            cd ${BACKUP_DIR}/database
            for dir in */; do
              dir_date=\${dir%/}  # Remove trailing slash
              if [ "\$dir_date" -lt "\$CUTOFF_DATE" ] 2>/dev/null; then
                echo "Deleting old backup: \$dir_date"
                rm -rf "\$dir_date"
              fi
            done

            echo "âœ… Cleanup completed"
          ENDSSH

      - name: Test backup integrity
        id: integrity-check
        env:
          SSH_PRIVATE_KEY: ${{ secrets.PRODUCTION_SSH_KEY }}
          SERVER_HOST: ${{ secrets.PRODUCTION_SERVER }}
          SERVER_USER: ${{ secrets.PRODUCTION_USER }}
        run: |
          BACKUP_FILE="${{ steps.db-backup.outputs.backup_file }}"
          BACKUP_DATE="${{ steps.db-backup.outputs.backup_date }}"

          ssh -i ~/.ssh/deploy_key "$SERVER_USER@$SERVER_HOST" << ENDSSH
            cd /opt/scholarship-system

            # Verify checksum
            cd ${BACKUP_DIR}/database/${BACKUP_DATE}
            if sha256sum -c ${BACKUP_FILE}.sha256; then
              echo "âœ… Checksum verification passed"
            else
              echo "::error::Checksum verification failed"
              exit 1
            fi

            # Test backup can be restored (to temporary database)
            docker compose exec -T postgres psql -U scholarship_user -d postgres << 'EOSQL'
              DROP DATABASE IF EXISTS backup_test;
              CREATE DATABASE backup_test;
          EOSQL

            # Decompress and restore backup
            gunzip -c ${BACKUP_DIR}/database/${BACKUP_DATE}/${BACKUP_FILE} | \
              docker compose exec -T postgres pg_restore \
                -U scholarship_user \
                -d backup_test \
                --no-owner \
                2>&1 | head -20

            # Verify tables exist
            TABLE_COUNT=\$(docker compose exec -T postgres psql \
              -U scholarship_user \
              -d backup_test \
              -t -c "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';" | tr -d ' ')

            echo "Tables in restored backup: \$TABLE_COUNT"

            if [ "\$TABLE_COUNT" -gt 0 ]; then
              echo "âœ… Backup integrity verified (\$TABLE_COUNT tables)"
            else
              echo "::error::Backup integrity check failed (no tables found)"
              exit 1
            fi

            # Cleanup test database
            docker compose exec -T postgres psql -U scholarship_user -d postgres \
              -c "DROP DATABASE backup_test;"

            echo "success=true" >> $GITHUB_OUTPUT
          ENDSSH

  backup-files:
    name: Backup Application Files
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'schedule' ||
      github.event.inputs.backup_type == 'full' ||
      github.event.inputs.backup_type == 'files-only'

    steps:
      - name: Backup uploaded files and configs
        id: files-backup
        env:
          SSH_PRIVATE_KEY: ${{ secrets.PRODUCTION_SSH_KEY }}
          SERVER_HOST: ${{ secrets.PRODUCTION_SERVER }}
          SERVER_USER: ${{ secrets.PRODUCTION_USER }}
        run: |
          BACKUP_TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          BACKUP_DATE=$(date +%Y%m%d)
          BACKUP_FILE="files-backup-${BACKUP_TIMESTAMP}.tar.gz"

          mkdir -p ~/.ssh
          echo "$SSH_PRIVATE_KEY" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H "$SERVER_HOST" >> ~/.ssh/known_hosts

          # Create files backup on server
          ssh -i ~/.ssh/deploy_key "$SERVER_USER@$SERVER_HOST" << ENDSSH
            # Ensure backup directory exists
            sudo mkdir -p ${BACKUP_DIR}/files/${BACKUP_DATE}
            sudo chown -R $SERVER_USER:$SERVER_USER ${BACKUP_DIR}
            chmod 750 ${BACKUP_DIR}

            cd /opt/scholarship-system

            # Backup uploaded files, configs, and important data
            tar -czf ${BACKUP_DIR}/files/${BACKUP_DATE}/${BACKUP_FILE} \
              backend/uploads/ \
              docker-compose.yml \
              .env \
              2>/dev/null || true

            # Verify backup was created
            if [ -f ${BACKUP_DIR}/files/${BACKUP_DATE}/${BACKUP_FILE} ]; then
              BACKUP_SIZE=\$(du -h ${BACKUP_DIR}/files/${BACKUP_DATE}/${BACKUP_FILE} | cut -f1)
              echo "âœ… Files backup created: ${BACKUP_FILE} (\${BACKUP_SIZE})"
              echo "ðŸ“ Location: ${BACKUP_DIR}/files/${BACKUP_DATE}/${BACKUP_FILE}"

              # Set permissions for IT access
              chmod 640 ${BACKUP_DIR}/files/${BACKUP_DATE}/${BACKUP_FILE}

              # Create checksum
              cd ${BACKUP_DIR}/files/${BACKUP_DATE}
              sha256sum ${BACKUP_FILE} > ${BACKUP_FILE}.sha256
              echo "ðŸ” Checksum created"
            else
              echo "::error::Failed to create files backup"
              exit 1
            fi
          ENDSSH

          echo "backup_file=${BACKUP_FILE}" >> $GITHUB_OUTPUT
          echo "backup_date=${BACKUP_DATE}" >> $GITHUB_OUTPUT

      - name: Cleanup old file backups
        env:
          SSH_PRIVATE_KEY: ${{ secrets.PRODUCTION_SSH_KEY }}
          SERVER_HOST: ${{ secrets.PRODUCTION_SERVER }}
          SERVER_USER: ${{ secrets.PRODUCTION_USER }}
          RETENTION: ${{ github.event.inputs.retention_days || env.RETENTION_DAYS }}
        run: |
          ssh -i ~/.ssh/deploy_key "$SERVER_USER@$SERVER_HOST" << ENDSSH
            # Calculate cutoff date
            CUTOFF_DATE=\$(date -d "${RETENTION} days ago" +%Y%m%d)
            echo "ðŸ—‘ï¸  Cleaning up file backups older than \${CUTOFF_DATE}"

            # Find and delete old backup directories
            cd ${BACKUP_DIR}/files
            for dir in */; do
              dir_date=\${dir%/}
              if [ "\$dir_date" -lt "\$CUTOFF_DATE" ] 2>/dev/null; then
                echo "Deleting old backup: \$dir_date"
                rm -rf "\$dir_date"
              fi
            done

            echo "âœ… Cleanup completed"
          ENDSSH

  verify-backups:
    name: Verify & Report Backups
    needs: [backup-database, backup-files]
    if: always()
    runs-on: ubuntu-latest

    steps:
      - name: List and verify backups on server
        id: list-backups
        env:
          SSH_PRIVATE_KEY: ${{ secrets.PRODUCTION_SSH_KEY }}
          SERVER_HOST: ${{ secrets.PRODUCTION_SERVER }}
          SERVER_USER: ${{ secrets.PRODUCTION_USER }}
        run: |
          mkdir -p ~/.ssh
          echo "$SSH_PRIVATE_KEY" > ~/.ssh/deploy_key
          chmod 600 ~/.ssh/deploy_key
          ssh-keyscan -H "$SERVER_HOST" >> ~/.ssh/known_hosts

          # List backups and calculate sizes
          ssh -i ~/.ssh/deploy_key "$SERVER_USER@$SERVER_HOST" << 'ENDSSH'
            echo "ðŸ“¦ Backup Inventory"
            echo "===================="
            echo ""
            echo "ðŸ“ Location: ${BACKUP_DIR}"
            echo ""

            # Database backups
            echo "ðŸ—„ï¸  Database Backups:"
            if [ -d "${BACKUP_DIR}/database" ]; then
              cd ${BACKUP_DIR}/database
              for dir in */; do
                if [ -d "$dir" ]; then
                  echo "  ðŸ“… ${dir%/}:"
                  find "$dir" -type f -name "*.sql.gz" -exec du -h {} \; | \
                    sed 's/^/    /'
                fi
              done
              TOTAL_DB_SIZE=$(du -sh . 2>/dev/null | cut -f1)
              echo ""
              echo "  Total database backups size: ${TOTAL_DB_SIZE}"
            else
              echo "  No database backups found"
            fi

            echo ""
            echo "ðŸ“ File Backups:"
            if [ -d "${BACKUP_DIR}/files" ]; then
              cd ${BACKUP_DIR}/files
              for dir in */; do
                if [ -d "$dir" ]; then
                  echo "  ðŸ“… ${dir%/}:"
                  find "$dir" -type f -name "*.tar.gz" -exec du -h {} \; | \
                    sed 's/^/    /'
                fi
              done
              TOTAL_FILES_SIZE=$(du -sh . 2>/dev/null | cut -f1)
              echo ""
              echo "  Total file backups size: ${TOTAL_FILES_SIZE}"
            else
              echo "  No file backups found"
            fi

            echo ""
            echo "ðŸ’¾ Total Backup Storage:"
            du -sh ${BACKUP_DIR} 2>/dev/null || echo "  Unable to calculate"
          ENDSSH

      - name: Generate backup manifest for IT
        env:
          SSH_PRIVATE_KEY: ${{ secrets.PRODUCTION_SSH_KEY }}
          SERVER_HOST: ${{ secrets.PRODUCTION_SERVER }}
          SERVER_USER: ${{ secrets.PRODUCTION_USER }}
        run: |
          TODAY=$(date +%Y%m%d)

          ssh -i ~/.ssh/deploy_key "$SERVER_USER@$SERVER_HOST" << ENDSSH
            # Create manifest file for IT to reference
            MANIFEST_FILE="${BACKUP_DIR}/backup-manifest-${TODAY}.txt"

            cat > "\${MANIFEST_FILE}" <<'MANIFEST'
====================================================================
Scholarship System - Backup Manifest
Generated: $(date '+%Y-%m-%d %H:%M:%S %Z')
====================================================================

BACKUP LOCATION: ${BACKUP_DIR}

âš ï¸  ACTION REQUIRED BY IT:
   These backups are stored on the production server and should be
   transferred to external backup storage according to the backup policy.

====================================================================
DATABASE BACKUPS
====================================================================

MANIFEST

            # List database backups
            if [ -d "${BACKUP_DIR}/database" ]; then
              cd ${BACKUP_DIR}/database
              for dir in */; do
                if [ -d "\$dir" ]; then
                  echo "Date: \${dir%/}" >> "\${MANIFEST_FILE}"
                  find "\$dir" -type f \( -name "*.sql.gz" -o -name "*.sha256" \) \
                    -exec ls -lh {} \; | \
                    awk '{printf "  - %s %s %s (%s)\n", \$9, \$6, \$7, \$5}' >> "\${MANIFEST_FILE}"
                  echo "" >> "\${MANIFEST_FILE}"
                fi
              done
            fi

            cat >> "\${MANIFEST_FILE}" <<'MANIFEST'
====================================================================
FILE BACKUPS
====================================================================

MANIFEST

            # List file backups
            if [ -d "${BACKUP_DIR}/files" ]; then
              cd ${BACKUP_DIR}/files
              for dir in */; do
                if [ -d "\$dir" ]; then
                  echo "Date: \${dir%/}" >> "\${MANIFEST_FILE}"
                  find "\$dir" -type f \( -name "*.tar.gz" -o -name "*.sha256" \) \
                    -exec ls -lh {} \; | \
                    awk '{printf "  - %s %s %s (%s)\n", \$9, \$6, \$7, \$5}' >> "\${MANIFEST_FILE}"
                  echo "" >> "\${MANIFEST_FILE}"
                fi
              done
            fi

            cat >> "\${MANIFEST_FILE}" <<'MANIFEST'
====================================================================
CHECKSUM VERIFICATION
====================================================================

To verify backup integrity before transfer:

  cd ${BACKUP_DIR}/database/YYYYMMDD
  sha256sum -c database-backup-*.sha256

  cd ${BACKUP_DIR}/files/YYYYMMDD
  sha256sum -c files-backup-*.sha256

====================================================================
TRANSFER INSTRUCTIONS FOR IT
====================================================================

1. Verify checksums before transfer
2. Transfer entire daily directories to backup storage
3. Verify transfer completion
4. Files are kept on server for ${RETENTION_DAYS} days
5. After successful external backup, old files are auto-cleaned

====================================================================
MANIFEST

            chmod 644 "\${MANIFEST_FILE}"
            echo "âœ… Manifest created: \${MANIFEST_FILE}"

            # Display manifest
            cat "\${MANIFEST_FILE}"
          ENDSSH

      - name: Generate backup report
        run: |
          cat >> $GITHUB_STEP_SUMMARY <<EOF
          # ðŸ’¾ Backup Report

          ## Status

          - Database Backup: ${{ needs.backup-database.result == 'success' && 'âœ… Success' || 'âŒ Failed' }}
          - Files Backup: ${{ needs.backup-files.result == 'success' && 'âœ… Success' || 'âŒ Failed' }}

          ## Details

          - **Timestamp**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')
          - **Backup Type**: ${{ github.event.inputs.backup_type || 'Scheduled (Full)' }}
          - **Retention on Server**: ${{ github.event.inputs.retention_days || env.RETENTION_DAYS }} days
          - **Server**: ${{ secrets.PRODUCTION_SERVER }}

          ## Backup Location

          \`\`\`
          ${BACKUP_DIR}/
          â”œâ”€â”€ database/
          â”‚   â””â”€â”€ $(date +%Y%m%d)/
          â”‚       â”œâ”€â”€ database-backup-*.sql.gz
          â”‚       â””â”€â”€ database-backup-*.sha256
          â””â”€â”€ files/
              â””â”€â”€ $(date +%Y%m%d)/
                  â”œâ”€â”€ files-backup-*.tar.gz
                  â””â”€â”€ files-backup-*.sha256
          \`\`\`

          ## For IT Department

          âš ï¸ **Action Required**: Backups are ready for transfer to external storage.

          - Manifest file: \`${BACKUP_DIR}/backup-manifest-$(date +%Y%m%d).txt\`
          - Verify checksums before transfer
          - Transfer entire daily directories
          - Backups auto-cleanup after ${RETENTION_DAYS} days

          ## Next Scheduled Backup

          - Daily: 02:00 UTC
          - Additional: Every 6 hours

          ## Restore Instructions

          See production documentation for restore procedures.
          EOF

      - name: Notify on failure
        if: needs.backup-database.result == 'failure' || needs.backup-files.result == 'failure'
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'ðŸš¨ Production Backup Failed',
              body: `
              ## Backup Failure

              One or more backup jobs have failed.

              - Database Backup: ${{ needs.backup-database.result }}
              - Files Backup: ${{ needs.backup-files.result }}

              **Timestamp**: ${new Date().toISOString()}

              [View Workflow Run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

              ## Action Required

              1. Check workflow logs for errors
              2. Verify server disk space
              3. Check database connectivity
              4. Retry backup immediately
              5. Notify IT if issue persists

              ## Server Information

              - Server: ${{ secrets.PRODUCTION_SERVER }}
              - Backup Directory: \`${BACKUP_DIR}\`
              `,
              labels: ['production', 'backup', 'urgent']
            })
